{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nasdaq Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock price data maipulation, visualisation and machine learning on Nasdaq listed companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import all the relevant modules required. Set up the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_datareader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b2a48e72eef9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_datareader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mweb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_datareader'"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import datetime as dt\n",
    "import os\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn import svm, model_selection, neighbors\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by collecting the tickers for all the Nasdaq listed companies.\n",
    "\n",
    "vist Wiki page, get response which has the source code\n",
    "turn the .text attribute to soup using BeautifulSoup\n",
    "(BS turns source code to a BS object that you can treat more like Python object)\n",
    "\n",
    "the specific solution to searching through the wiki table on that specific page\n",
    "had to look into the sourcecode\n",
    "we find in html the table has class=\"wikitable sortable\"\n",
    "\n",
    "for each row after header row, ticker is table data td, grab .text of it and append to tickers list\n",
    "\n",
    "save the tickers list with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_nasdaq_tickers():\n",
    "    resp = requests.get('https://en.wikipedia.org/wiki/NASDAQ-100')\n",
    "    soup = bs.BeautifulSoup(resp.text, 'lxml')\n",
    "\n",
    "    table = soup.find('table', {'class': 'wikitable sortable'})\n",
    "   \n",
    "    tickers = []\n",
    "    for row in table.findAll('tr')[1:]:\n",
    "        ticker = row.findAll('td')[1].text[:-1]\n",
    "        tickers.append(ticker)\n",
    "\n",
    "    with open(\"nasdaqtickers.pickle\",\"wb\") as f:\n",
    "        pickle.dump(tickers,f)\n",
    "\n",
    "    print(tickers)\n",
    "\n",
    "    return tickers\n",
    "\n",
    "save_nasdaq_tickers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, collect the data from the Nasdaq list from Yahoo Finance.\n",
    "\n",
    "handle for whether or not to reload the nasdaq list\n",
    "if we ask it to, program will re-pull nasdaq list\n",
    "else, use our pickle\n",
    "\n",
    "we want to pull all the data from Yahoo for every sock and save it\n",
    "first, create new directory with stock data per company\n",
    "\n",
    "pull the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nasdaq_data_from_yahoo(reload_nasdaq=False):\n",
    "    if reload_nasdaq:\n",
    "        tickers = save_nasdaq_tickers()\n",
    "    else:\n",
    "        with open(\"nasdaqtickers.pickle\", \"rb\") as f:\n",
    "            tickers = pickle.load(f)\n",
    "\n",
    "    if not os.path.exists('stock_dfs'):\n",
    "        os.makedirs('stock_dfs')\n",
    "\n",
    "    start = dt.datetime(2017, 1, 1)\n",
    "    end = dt.datetime.now()\n",
    "    for ticker in tickers:\n",
    "        print(ticker)\n",
    "        if not os.path.exists('stock_dfs/{}.csv'.format(ticker)):\n",
    "            df = web.DataReader(ticker, 'yahoo', start, end)\n",
    "            df.reset_index(inplace=True)\n",
    "            df.set_index(\"Date\", inplace=True)\n",
    "            df.to_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        else:\n",
    "            print('Already have {}'.format(ticker))\n",
    "            \n",
    "get_nasdaq_data_from_yahoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the data with Pandas.\n",
    "join stock datasets together\n",
    "\n",
    "pull previously made list of tickers, begin with an empty dataframe called main_df\n",
    "\n",
    "read in each stock's dataframe\n",
    "\n",
    "we are only interested in the Adj Close data\n",
    "\n",
    "if there is nothing in main_df,  then start with current df, otherwise, use the Pandas join function\n",
    "\n",
    "output the count of the current ticker if it's evenly divisible by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data():\n",
    "    with open(\"nasdaqtickers.pickle\",\"rb\") as f:\n",
    "        tickers = pickle.load(f)\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    for count, ticker in enumerate(tickers):\n",
    "        df = pd.read_csv('stock_dfs/{}.csv'.format(ticker))\n",
    "        df.set_index('Date', inplace=True)\n",
    "\n",
    "        df.rename(columns={'Adj Close': ticker}, inplace=True)\n",
    "        df.drop(['Open', 'High', 'Low', 'Close', 'Volume'], 1, inplace=True)\n",
    "        \n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df, how='outer')\n",
    "\n",
    "        if count % 10 == 0:\n",
    "            print(count)\n",
    "\n",
    "    print(main_df.head())\n",
    "    main_df.to_csv('nasdaq_joined_closes.csv')\n",
    "    \n",
    "comile_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Form a heatmap of the data.\n",
    "\n",
    "build a correlation table from the nasdaq_joined_closes data, save into csv\n",
    " \n",
    "make a heatmap:\n",
    "\n",
    "first, need actual data itself to graph\n",
    "get numpy array of just the values (which are correlation numbers)\n",
    "\n",
    "build the figure and axis\n",
    "\n",
    "create the heatmap with pcolor\n",
    "use the RdYlGn colormap - gives red for negative correlations, green for positive correlations,\n",
    "yellow for no-correlations\n",
    "\n",
    "set x and y axis so we know which companies are which\n",
    "create tick markers\n",
    "\n",
    "flip yaxis so that graph is easier to read (as there is more space between x's and y's\n",
    "flip xaxis to be at top of graph (to make it more like a correlation table)\n",
    "\n",
    "add company names to currently nameless ticks:\n",
    "\n",
    "rotate xtics, which are the actual tickers themselves, as they would normally be written out horizontally\n",
    "tell color map that range is from -1 to +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data():\n",
    "    df = pd.read_csv('nasdaq_joined_closes.csv')\n",
    "\n",
    "    df_corr = df.corr()\n",
    "    print(df_corr.head())\n",
    "    df_corr.to_csv('nasdaq_corr.csv')\n",
    "\n",
    "    data1 = df_corr.values\n",
    "\n",
    "    fig1 = plt.figure()\n",
    "    ax1 = fig1.add_subplot(111)\n",
    "\n",
    "    heatmap1 = ax1.pcolor(data1, cmap=plt.cm.RdYlGn)\n",
    "    fig1.colorbar(heatmap1)\n",
    "\n",
    "    ax1.set_xticks(np.arange(data1.shape[1]) + 0.5, minor=False)\n",
    "    ax1.set_yticks(np.arange(data1.shape[0]) + 0.5, minor=False)\n",
    "\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.xaxis.tick_top()\n",
    "\n",
    "    column_labels = df_corr.columns\n",
    "    row_labels = df_corr.index\n",
    "    ax1.set_xticklabels(column_labels)\n",
    "    ax1.set_yticklabels(row_labels)\n",
    "\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap1.set_clim(-1,1)\n",
    "    plt.tight_layout()\n",
    "    # plt.savefig(\"correlations.png\", dpi = (300))\n",
    "    plt.show()\n",
    "\n",
    "visualise_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data to create labels.\n",
    "function takes one ticker as parameter\n",
    "\n",
    "each model is trained on a single company\n",
    "next we need to know number of days into the future we need prices for (7 days)\n",
    "read in data for close prices for all companies saved in past\n",
    "get list of existing tickers\n",
    "fill any missing with 0 for now\n",
    "now we want to grab the % changed values for next 7 days\n",
    "\n",
    "create dataframe columns for specific ticker using string formatting to create custom names\n",
    "get future values with .shift which shifts a column up or down\n",
    "shift a negative amount which will take that column and would shift column up by i rows\n",
    "gives future values i days in advanced which can calculate percentage change against\n",
    "\n",
    "return tickers and dataframe\n",
    "now we can have some feature sets that the algorithms can use to find relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_labels(ticker):\n",
    "    hm_days = 7\n",
    "    df = pd.read_csv('nasdaq_joined_closes.csv', index_col=0)\n",
    "    tickers = df.columns.values.tolist()\n",
    "    df.fillna(0, inplace=True)\n",
    "  \n",
    "    for i in range(1, hm_days + 1):\n",
    "        df['{}_{}d'.format(ticker, i)] = (df[ticker].shift(-i) - df[ticker]) / df[ticker]\n",
    "   \n",
    "    df.fillna(0, inplace=True)\n",
    "    return tickers, df\n",
    "\n",
    "process_data_for_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The buy, sell hold funciton.\n",
    "if the price rises more than 2% in the next 7 days - this is a buy\n",
    "if it drops more than 2% in next 7 days - this is a sell\n",
    "if doesn't do either or these - this is a hold\n",
    "this will be mapped to a Pandas DataFrame column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buy_sell_hold(*args):\n",
    "    cols = [c for c in args]\n",
    "    requirement = 0.02\n",
    "    for col in cols:\n",
    "        if col > requirement:\n",
    "            return 1\n",
    "        if col < -requirement:\n",
    "            return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Featuresets.\n",
    "\n",
    "take any ticker, create the dataset, create the target column (the label)\n",
    "target column will have wither -1, 0 or  for each row\n",
    "get the distribution\n",
    "clean up data\n",
    "some data may be missing - replace with 0\n",
    "some data may be infinite - convert to NaN, and drop the NaN\n",
    "features metric should be the company's percent change that day instead of the day's price stocks\n",
    "(companies will change in price before others)\n",
    "convert stock prices to % changes\n",
    "\n",
    "create features and labels\n",
    "\n",
    "X contains featuresets (daily & changes for every Nasdaq company)\n",
    "y is the target (the label) - to map the featuresets to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_featuresets(ticker):\n",
    "    tickers, df = process_data_for_labels(ticker)\n",
    "\n",
    "    df['{}_target'.format(ticker)] = list(map( buy_sell_hold,\n",
    "                                               df['{}_1d'.format(ticker)],\n",
    "                                               df['{}_2d'.format(ticker)],\n",
    "                                               df['{}_3d'.format(ticker)],\n",
    "                                               df['{}_4d'.format(ticker)],\n",
    "                                               df['{}_5d'.format(ticker)],\n",
    "                                               df['{}_6d'.format(ticker)],\n",
    "                                               df['{}_7d'.format(ticker)] ))\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    df_vals = df[[ticker for ticker in tickers]].pct_change()\n",
    "    df_vals = df_vals.replace([np.inf, -np.inf], 0)\n",
    "    df_vals.fillna(0, inplace=True)\n",
    "\n",
    "    X = df_vals.values\n",
    "    y = df['{}_target'.format(ticker)].values\n",
    "\n",
    "    return X,y,df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning with K-Nearest Neighours\n",
    "\n",
    "shuffle data, create training and testing samples\n",
    "apply K Nearest Neighbors classifer\n",
    "train classifier on data\n",
    "take X data and fit to the y data, for each pairs of X's an y's\n",
    "take some featuresets, X_test, make a prediction, see if it matches labels, y_test\n",
    "return percentage accuracy in decimal form\n",
    "print accuracy\n",
    "get predictions of X_testdata, output distribution using counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning_KNNC(ticker):\n",
    "    X, y, df = extract_featuresets(ticker)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "    clf = neighbors.KNeighborsClassifier()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    confidence = clf.score(X_test, y_test)\n",
    "\n",
    "    print('~ results with K nearest neighbours classifier for', ticker, '~')\n",
    "    print('accuracy:',confidence)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print('predicted class counts:',Counter(predictions))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning with voting classifier. Procedure is similar to the method above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def machine_learning_VC(ticker):\n",
    "    X, y, df = extract_featuresets(ticker)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25)\n",
    "    clf = VotingClassifier([('lsvc', svm.LinearSVC()),\n",
    "                            ('knn', neighbors.KNeighborsClassifier()),\n",
    "                            ('rfor', RandomForestClassifier())])\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    confidence = clf.score(X_test, y_test)\n",
    "    \n",
    "    print('~ results with voting classifier for', ticker, '~')\n",
    "    print('accuracy:',confidence)\n",
    "    predictions = clf.predict(X_test)\n",
    "    print('predicted class counts:',Counter(predictions))\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now we can apply the machine learning methods to the company GOOGL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning_KNNC('GOOGL')\n",
    "machine_learning_VC('GOOGL')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
